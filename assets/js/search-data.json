{
  
    
        "post0": {
            "title": "Photon Statistics",
            "content": "Because of the inherent probability quantum mechanics entails, photons arriving at some detector follow statistical properties. In this chapter I will discuss these Photon Statistics and the unintuitive way photons behave when they arrive sparsely. . Photon Noise . When looking at an astronomical object far away, the detector is measuring photons that this galaxy randomly emits. This means that in the context of radio astronomy our signal is noise[1]! When I talk about noise, I therefore don&#39;t mean the &#39;traditional&#39; understanding of noise as static drowning out the song on the radio, but rather photon noise: our signal. . This noise can be split up into two categories: thermal noise and shot noise. In this section I will take a look at both . Thermal Noise . In radio receivers, a big part of the noise is generated by thermal agitation of electrons. In most uses this can be classified as white noise: the power is constant across its frequency spectrum [2], but in extremely high frequencies or low temperatures this approximation doesn&#39;t hold. The power $P$ transmitted by the noise is given as Johnson-Nyquist Noise and is approximated for small bandwidths $ Delta nu$ as[3]: . $$ P_ nu= int_{ nu_0}^{ nu_1} frac{h nu}{e^{h nu/k_BT}-1}d nu approx frac{h nu}{e^{h nu/k_BT}-1} Delta nu $$Plotting this normalized ($P_ nu/k_BT$) power spectrum supports my earlier statements that, in most cases, thermal noise can be approximated as white . Unfortunately, this white noise approximation doesn&#39;t hold for the Terahertz range. Once more, it is also not the only form of noise we have to deal with. . Shot noise . Because the source is very dim, photons arrive one at a time. This means that we are dealing with shot noise[1]. Here the detection rate of a photon is characterized by Poisson statistics and the famous Poisson distribution (missing reference): . $$ f(x)= frac{ lambda^xe^{- lambda}}{x!} $$Hence we also call this noise Poisson noise. . Uncertainty . From Poisson statistics we know that the uncertainty $ sigma_N$ over a number of measurements is equal to the square root of these measurements, since it&#39;s an uncorrelated process (missing reference)[1]. Since our power arrives with single photons hitting the detector, the power follows the same uncertainty . $$ sigma_N= sqrt{N} $$$$ sigma_P propto sqrt{P} $$However, if we look at Johnson-Nyquist noise and approximate for lower frequencies we get[1][3]: . $$ P approx frac{h nu}{e^{h nu/k_BT}-1} Delta nu approx k_BT Delta nu $$$$ sigma_P propto P $$Hence we have found two proportionality relations for the uncertainty, which is it? . Particle-Wave duality . The seemingly paradoxical nature of this uncertainty can be explained as a caveat of the particle-wave duality. In the wave domain the Johnson-Nyquist noise dominates, whereas in the particle domain we get mainly Poisson noise. The general case of the uncertainty in the number of photons arriving in a detection time of $ tau$ is(missing reference)[4]: . $$ sigma_ mathrm{ph}= frac{1}{ sqrt{ tau}} sqrt{n^2+n} $$with $n$, the photon number, being the number of photons per time per bandwidth. Here both extremes are more obvious: for $n gg 1$ we get the thermal noise from the wave domain and for $n ll 1$ the Poisson uncertainty falls out. . (missing reference)An analogy for the detection of photons in the particle and wave limit. . The photon number for a thermal blackbody radiator is given by the Bose-Einstein equation [5][4] . $$ n_ mathrm{th} left( nu,T right)= frac{1}{e^{h nu/k_BT}-1} $$Which means that in the region between $220 :{ mathrm{GHz}}$ and $450 :{ mathrm{GHz}}$ for a relatively hot object the photon occupation number is neither fully in the wave limit nor the particle limit. . Finally, another source for noise needs discussing. Mainly in the wave domain, where the photon number is higher, photons tend to come clumped together in a process known as photon bunching[4]. . Photon Bunching . Quantum Electrodynamics has taught us that photons behave stochastically, so it is reasonable to assume that photon detection also occurs randomly. While this is (obviously) true to some degree, in the previous section I stated photons can arrive &#39;clumped&#39; together at the detector in a phenomenon known as photon bunching. This means that detecting one photon will result in a higher chance of another photon being detected within a specified time, called the coherence time $t_{ mathrm{coh}}$ [4]. In this chapter I will first present an intuitive, qualitative explanation as to why photon bunching occurs. Then I will go deeper into the mathematics and quantum mechanics of photon bunching and the specific case of the DESHIMA system. . An analogy . To understand photon bunching, first think of photons arriving at the detector like raindrops falling on a piece of paper. While it&#39;s raining with constant intensity, the chance of a raindrop falling on a specific area within, say, the next second (expressed by $P( mathrm{drop})$) is constant. In the figure below I have set $P( mathrm{drop}) = 0.3$: . The raindrops fall uncorrelated: every second a new chance of $P( mathrm{drop})$ means a raindrop falling from the sky might land in our defined area. This is how unbunched, or random, photons behave. . Now let&#39;s assume the chance of a raindrop occurring is not constant over time, but rather varies relatively slowly over time. This could be because of varying wind speeds or varying intensity in the rain, but whatever the case the rain drops are no longer uncorrelated. There are moments of high intensity, where the chance of a raindrop is high and similarly there are moments of low intensity. I have simulated this using open simplex noise [6] in the following graph. . As is clear from the graph, the raindrops are clumped together. This is the same underlying principle as photon bunching in photons from astronomical sources. The random motion of the exciting atoms, for example Brownian motion, means that the intensity also fluctuates over time[4]. It is therefore not the act of detecting a photon that increases the chance of another detection, but rather an underlying change in probability of detecting, easily explained by probabilistics. . This means that at the point where a raindrop falls or a photon gets emitted, it is still a simple stochastic process. Should our sampling interval be much smaller than the time over which the rain varies, we&#39;d still see &#39;stochastic regions&#39;, where the probability function stays roughly constant, like in the first example. This is illustrated in the graph below with stretched noise: . The droplets appear less bunched, because the time scale in which the measurements take place is much smaller than the time scale in which the intensity changes. The very first example I spoke about, of raindrops falling at a constant intensity, is a situation in which this discrepancy occurs. Of course it won&#39;t rain forever and when the rain dies down the chance of a raindrop falling is much lower than while it&#39;s still raining. So while the droplets look purely random when it rains, they aren&#39;t over the course of the entire day. I will call this behavior bunched (slow timescale), because the sampling time is much faster than the coherence time, which I shall later elaborate on further. . Let&#39;s also take a look at what happens when the sampling time is much slower than the underlying probability shape. . As expected, the detection rate looks much like the first detection rate with constant $P left( mathrm{drop} right)$. Although the underlying probability changes, it changes too fast between detections for bunching to occur. . Intermezzo: Antibunching . While this report focuses on photon bunching, the opposite also occurs in, for example, single photon sources [7]. Now that I have discussed a framework with which to explain photon bunching, I thought it would be remiss to leave out an explanation for antibunching. . As one would expect, in antibunching the opposite of bunching happens: detecting a raindrop would mean that, at least for the next period of time, the chance of a raindrop becomes smaller. A good allegory for this is a dripping faucet. A small flow of water exits the faucet and, due to surface tension, pools up in a small droplet at the end. As the droplet gets bigger, the chance of it falling increases, but once it drips down it takes all water with it and the process starts anew. . This behavior corresponds with antibunching behavior in single photon sources[7]. Atoms are excited through an energy pump process. When this energy increases sufficiently they emit a photon and lose energy, ready to get excited again[4]. . Again, the detection of such single photons will display antibunching, but it is not the detection that triggers this cool-down period, it is the emission. . Coherence . If the underlying probability function is unknown (and quantum mechanically it is), how would we be able to quantify whether our detections are bunched. A possible heuristic we can use comes from signal processing. We could take the autocorrelation of the signals and compare them. Since the autocorrelation is the cross-correlation between the signal and a time-shifted copy, we&#39;d likely see the bunched signal display some sort of correlation for a delay that is around the timescale of the oscillations in the probability function. In the figure below I have correlated the detections described above with $t in[0,1000]$ and plotted these values for different time delays $h$ . As is clear from the graph, the bunched photons show some autocorrelation, with the longer timescale showing longer (bigger time shifts) autocorrelation. This can be explained further by signal analysis. We are working in the discrete domain and smaller sampling steps relative to the variation in the underlying probability will mean more correlation. . What this shows is temporal coherence, a property of light that describes the predictability over a timescale[1]. . Bandwidth . Up until now we have only looked at raindrops and other analogous detections, but when talking about photons we need to take frequency into account. Photons obey the Heisenberg uncertainty relation where the uncertainty in position $ Delta x$ and momentum $ Delta p_x$ must obey [1]: . $$ Delta x Delta p_x = frac{ hbar}{2} $$Our photons are flying at the detector, so it&#39;s uncertainty in longitudinal ($z$, towards the detector) position can be equated as it&#39;s uncertainty in detection time and it&#39;s momentum can be expressed as $h/ lambda$: . $$ Delta z Delta p_z= frac{ Delta t}{c} frac{h}{ Delta lambda} = frac{ Delta t}{c} frac{hc}{ Delta nu} = frac{ hbar}{2} $$and finally we arrive at . $$ Delta nu propto frac{1}{ Delta t} $$In other words: a shorter coherence time means more accurate knowledge on where the photons are, meaning their uncertainty in momentum and therefore bandwidth is bigger. . The reverse can also be seen experimentally. In Morgan and Mandel&#39;s 1966 paper[8], the authors explore the autocorrelation between two different light sources: a Hg198 source with a very narrow bandwidth (a) and a tungsten light bulb with a broad spectrum thermal source (b). . . Because the tungsten light has a high bandwidth, it has a short coherence time and the reverse is true for the Hg198 light. Therefore, if we take the short timescale bunched photons as an analogy for the tungsten light and the longer timescale bunched lights as analogous for the mercury light, we get something that looks very similar. . With a more thorough understanding of photon bunching, it is time to look return to photon noise and discuss noise-equivalent power. . Noise Equivalent power . The noise equivalent power ($ mathrm{NEP}$) is a way to express the sensitivity of a photon detectors. It is defined as the input signal power that results in a signal-to-noise-ratio of 1 in a 1 Hz output bandwidth. [9]. For our purposes this means multiplying the photon noise with the photon energy(missing reference). From [5] we have an equation for the electrical (detected) photon noise . $$ sigma_ mathrm{ph}^2= frac{1}{ tau} int_0^ infty eta( nu)n( nu) left[1+ eta( nu)n( nu) right]d nu $$multiplying this integral with the photon energy, we get the electrical Noise Equivalent Power added by photon noise for a specified integration time . $$ mathrm{NEP}_{ tau, mathrm{ph}}^2= frac{1}{ tau} int_0^ infty left(h nu right)^2 eta( nu)n( nu) left[1+ eta( nu)n( nu) right]d nu $$But unfortunately this integral is not easily solvable. As we&#39;ve seen in the previous section, the coherence time is inversely proportional to the bandwidth and by taking an integral we effectively have an infinitesimal bandwidth and therefore an infinite coherence time. . If we were to create a perfect box filter, and approximate the photon number as constant over this filter we can get around this. Let&#39;s first define this box function . $$ Pi^{ Delta nu}_{ nu_0}( nu)= left { begin{array}{ll} 1 &amp; | nu- nu_0| le frac{ Delta nu}{2} 0 &amp; mathrm{elsewhere} end{array} right. $$And then set $ eta( nu)= eta_0 Pi^{ Delta nu}_{ nu_0}( nu)$. When we assume we have a constant photon occupation number over this range, the equation simplifies to: . $$ mathrm{NEP}_{ tau, mathrm{ph}}^2= frac{1}{ tau} int_0^ infty left(h nu right)^2 eta_0 Pi^{ Delta nu}_{ nu_0}( nu)n( nu) left[1+ eta_0 Pi^{ Delta nu}_{ nu_0}( nu)n( nu) right]d nu = frac{1}{ tau} int_{ nu_0- frac{ Delta nu}{2}}^{ nu_0+ frac{ Delta nu}{2}} left(h nu right)^2 eta_0n left[1+ eta_0n right]d nu $$Which, for $ Delta nu ll nu$ approximates as: $$ mathrm{NEP}_{ tau, mathrm{ph}}^2= frac{1}{ tau} left(h nu_0 right)^2 eta_0n left[1+ eta_0n right] Delta nu $$ . In astrophysics it is convention to take an integration time of $ tau=0.5 : mathrm{[s]}$ which results in a Noise Equivalent Power of: . $$ mathrm{NEP}_{ tau=0.5 mathrm{s}, mathrm{ph}}=h nu_0 sqrt{2 eta_0n left(1+ eta_0n right) Delta nu} $$ DESHIMA . In actual measurements the photon occupation number isn&#39;t known, but we are able to deduce it from the power impinged on the detector. If we once again place a box filter in front of the detector, the photon number is of course equal to the total number of detected photons multiplied by the efficiency of the filter: . $$ P_ mathrm{KID}= eta_0 sum_ih nu_i $$Which, by virtue of our earlier assumptions is equal to $$ P_ mathrm{KID}= eta_0h nu_0n Delta nu $$ rearranging we get: $$ n = frac{P_ mathrm{KID}}{ eta_0h nu_0 Delta nu} $$ . Inserting this in the equation for $ mathrm{NEP}$ we get: . $$ mathrm{NEP}_{ tau=0.5 mathrm{s}, mathrm{ph}}= sqrt{2P_ mathrm{KID}h nu_0 + 2 frac{P_ mathrm{KID}^2}{ Delta nu}} $$Which is in agreement with [10] . Finer integration . 1 filter channel is thus approximated as a box integral, this isn&#39;t physically possible and therefore inaccurate. To improve on this we can choose to subdivide one (Gaussian profile) filter into a sum of multiple box filters, like a Riemann sum of the integral. This would result in a better approximation of the filter profile . Generation-Recombination Noise . Besides photon noise (both Poisson and bunching), another type of noise adds to our $NEP$: generation-recombination noise. This is a type of noise that occurs in superconductor-based pair-breaking photon detectors, as quasiparticles generate and recombine in a cooper pair (missing reference). For our purposes we will take the noise equivalent power of recombination noise $ mathrm{NEP}&lt;/em&gt; mathrm{GR}$ as given by [10]: . $$ mathrm{NEP}_ mathrm{GR}= sqrt{4 Delta_ mathrm{Al} frac{P_ mathrm{KID}}{ eta_ mathrm{pb}}} $$Since the photon noise $ mathrm{NEP}_ mathrm{ph}$ and the recombination noise $ mathrm{NEP}_ mathrm{GR}$ are uncorrelated, we add them together by quadrature addition, the total noise equivalent power is thus given by: . $$ mathrm{NEP}_{ tau=0.5 mathrm{s}} = sqrt{ mathrm{NEP}_{ tau=0.5 mathrm{s}, mathrm{ph}}^2 + mathrm{NEP}_ mathrm{GR}^2} $$$$ mathrm{NEP}_{ tau=0.5 mathrm{s}}= sqrt{2P_ mathrm{KID}h nu_0 + 2 frac{P_ mathrm{KID}^2}{ Delta nu}+4 Delta_ mathrm{Al} frac{P_ mathrm{KID}}{ eta_ mathrm{pb}}} $$",
            "url": "https://joristiebosch.github.io/blog/jupyter/2022/01/05/Photon-statistics.html",
            "relUrl": "/jupyter/2022/01/05/Photon-statistics.html",
            "date": " • Jan 5, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Introduction",
            "content": "If you ask a historian (with a lot of fantasy) to name the holy grail of equipment in their field, they just might answer a time machine. While historians can infer a lot from written texts and archaeological digs, no substitute could best the simple act of being in the past and observing. Unfortunately for historians, a time machine is yet to be invented. Astronomers, however, are lucky in this field. . In September 1905 Albert Einstein published his famous paper &quot;On the Electrodynamics of moving Bodies&quot;[1] in which he posed the theory of special relativity. While it was known from electromagnetism that the speed of light is a constant, it wasn&#39;t understood how light travels at the same speed regardless of which direction light was fired in. What Einstein discovered was almost analogous to the geocentric model of the solar system of old: whichever way you look out to in the cosmos, you&#39;re looking into the past. . Since light is a wave, it undergoes Doppler shift and therefore cosmological objects that move away from the observer undergo a shift in the frequency of light. This is known as redshift, because the wavelength expands meaning that visible light would shift towards the red end of the spectrum. Just 12 years after Einstein&#39;s discovery, American Astronomer Vesto Slipher [2] discovered the redshift of distant galaxies and with it cosmological spectroscopy was born. . . [3]A part of the light spectrum. Visible light is expanded to show the different colors. Note how red light in the visible spectrum has a longer wavelength, giving redshift its name. . Combine cosmological redshift and special relativity and we get a sort of astronomical time machine: looking far out into the cosmos means we are looking into the past where the universe was much younger. However, just pointing a telescope at the night sky poses a few problems. . Cosmological formation . Understanding how stars and galaxies form out of a uniformly gaseous universe is one of the biggest areas of research in modern physical cosmology. The physical processes by which these happen might be well understood, but the amount of possible initial values of these processes are so vast that they can have wildly different outcomes[4]. Looking at these events occurring in the distant past (and therefore distant universe) is therefore the main instruments astronomers have. . Unfortunately, the formation of these cosmological bodies happen inside thick dust clouds which are opaque to visible light and are therefore investigated using what is called sub-millimeter astronomy: astronomy ranging from $200 : mathrm{ mu m}$ to about $1 : mathrm{mm}$. In frequency terms, following . $$ f = frac{c}{ lambda} $$this corresponds with about $300 : mathrm{GHz}$ to $1500 : mathrm{GHz}$. . [5]The Messer-16 nebula, dubbed &quot;The Eagle&quot;, captured by the Hubble Space Telescope is an example of a dust cloud that is opaque to visible light . Redshift . As mentioned before, the redshift of light gives us the opportunity to calculate the relative speed and therefore distance and age of astronomical sources. When I talk about redshift, I mean the following formal definition [6] . $$ 1+z = frac{f_ mathrm{emit}}{f_ mathrm{obs}} $$where $z$ denotes redshift and $f_ mathrm{emit}$ and $f_ mathrm{obs}$ denote the emitted and observed frequency of a signal respectively. In order to calculate redshift we therefore need to know both frequencies. . Emitted frequency . Quantum mechanics tells us that the electron configuration in atoms exist in quantized states: that is they can move between defined states, but not in the continuum between. When an atom moves from one configuration to a higher state, energy is absorbed, when it moves to a lower state energy is emitted. These quantized energy states give way to what is known as spectral lines, where a specific wavelength is known to be emitted by specific atoms. . [7]A few energy states of carbon. Note how higher energy gaps result in shorter wavelengths. . This becomes clear when we look at the spectral flux density $E_{e, nu}$ of a galaxy, simulated with the Python module galspec[8]. . /opt/conda/lib/python3.9/site-packages/galspec/spectrumCreate.py:48: RuntimeWarning: overflow encountered in double_scalars return (2*h*(v*v*v))/(c*c*exp((h*v)/(k*T)) - 1) /opt/conda/lib/python3.9/site-packages/galspec/spectrumCreate.py:48: RuntimeWarning: overflow encountered in exp return (2*h*(v*v*v))/(c*c*exp((h*v)/(k*T)) - 1) . Beside broad spectrum thermal noise the galaxy emits spectral peaks. From the figure it is clear that with higher $z$ the peaks move further to the left, towards lower frequencies and therefore higher wavelengths. If one were to look for peaks in incoming signal and measure the wavelength at which these peaks occur, the redshift and thus age of a galaxy can be detected. . Observed frequency . In order to know the wavelength of these spectral lines at our detection point, we need to measure the specific frequency of an incoming photon in a spectrometer. This can be done using a Coherent Heterodyne receiver, except that these devices work to a frequency of about $36 : mathrm{Ghz}$[9], much lower than the spectral lines we are interested in as shown above. . Traditional photon detectors, at their core, work by converting an incoming photon into an electrical current, which means that the specific momentum, energy or frequency of the photon is lost. A way around this is to move the incoming photons depending on their wavelength, such as happens in an optical prism. . [10]When a photon enters the prism, its angle changes depending on its wavelength. . This is how a lot of spectrometers work, but due to the large wavelengths and high redshift range ($1+z approx1-10$)[11] of the signals involved in galaxy spectroscopy this approach is not feasible. . DESHIMA . DESHIMA, short for the Deep Spectroscopic High-Redshift Mapper, is a spectrometer developed by a team at the TU Delft that takes another approach(missing reference)[12]. DESHIMA uses a series of bandpass filters on a supercooled chip to direct incoming photons into bins, where they are detected by photomultipliers. The advantage of this approach is that the spectrometer itself is really small, taking up just a few squared centimeters[11] and is easily scalable to multiple octaves(missing reference). . [13]A schematic overview of the DESHIMA 2.0 chip . DESHIMA is placed on ASTE, a ground-based sub-millimeter telescope near the ALMA site in the Atacama Desert. . [14]A panoramic shot from the ASTE site in the Atacama Desert. . Ground-based astronomy . While the ASTE site is high up in the Atacama desert, the telescope still needs to look through some atmosphere when doing observations. Since cosmological object of interest is often far away and very cold, it is much dimmer than the effects from the atmosphere. The atmosphere is almost completely opaque at some frequencies DESHIMA operates in and loads the antenna dish because it is much hotter than the astronomical source. . Below the atmospheric loading at the ASTE site is calculated by the software package deshima-sensitivity[15] and plotted with a galaxy spectrum synthesized by galspec: . The atmosphere is over 3 orders of magnitude brighter than the galaxy spectrum before the latter is attenuated. After the atmospheric attenuation the difference is even bigger. Therefore modeling the expected loading from the atmosphere and the entire chain from antenna to detector is important to be able to do measurements and to find the signal within the noise. deshima-sensitivity[15] was designed to do this, but takes some approximations that were deemed to be reductive. . This Project . The current version of deshima-sensitivity does not take filter profiles into consideration when calculating the power received on each channel. It samples the power spectral density calculated to be at the filter&#39;s center frequency and multiplies this with the filter bandwidth, creating a crude box filter. While this approach holds for flat power spectra, it doesn&#39;t quite hold for spectra like the one above. . In this project I will modify the existing deshima-sensitivity package to more accurately resemble the DESHIMA 2.0 filter profiles and therefore the spectrometer as a whole. In order to do so, I first will dive into the DESHIMA system in more depth and then give a brief but thorough overview of photon statistics and the associated noise. Finally I will model the system and compare it with previous versions and measurement results from DESHIMA 2.0. .",
            "url": "https://joristiebosch.github.io/blog/jupyter/2022/01/04/Introduction.html",
            "relUrl": "/jupyter/2022/01/04/Introduction.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Technical information on how this blog is made",
            "content": "Introduction . This blog is written using fastpages[1], an easy-to-use (and to setup) way to convert Jupyter Notebooks to blogs, which are automatically hosted on a Github Pages website. This post serves as an introduction for potential users, as a way for me to test some things and as a reference for some more obscure parts of the Fastpages process. Let&#39;s begin! . Note: Every post will have a link to the source in the top right. Both a google Colab link for an editor or a Github link to download the raw file . Why Fastpages? . A big part of my thesis will be working in python, specifically in Jupyter Notebooks. These are great ways to blend python scripts with markdown and some $ LaTeX$ features, meaning that in one cell I can mathmatically derive some expression and in the next I can script it in Python. This back and forth got me thinking about using these notebooks as the foundation for my thesis, which led me to fastpages. This means that if I write proper jupyter notebooks, I will be able to: . Work on the problem at hand | Share the problem at hand in a more informal way | Copy-paste a section straight into my final report | . all from the same source file. Sounds great! . However, there are some limitations to vanilla fastpages . Pedantic Limitations and how to solve them . Equations . Using jupyter notebooks you can enter inline math, for example for variables like $x$ and $ eta_{NEP}$ by using the syntax $some expression$, just like you would do in $ LaTeX$ markdown files. However a centered function . $$ Complicated math $$ . will not be numbered and is not referenceable. Thankfully Anthoine C.[2] gave the solution, which is to override the default mathrenderer with a couple of lines of code and that seemed to do the trick. . $$ i hbar frac{ partial mathbf{ Psi}(x,t)}{ partial t}= left(- frac{ hbar}{2m} frac{ partial^2}{ partial x^2}+V(x,t) right) mathbf{ Psi}(x,t) label{Schrodinger} $$ and as we can see in eqref{Schrodinger}, we have a beatifully typeset, referenced Schrodinger Equation. However, as we can see from the Identity matrix in $ mathbb{R}^4$ eqref{I_R4}, the equation reference varies in size with the size of the equation, so maybe don&#39;t throw away your favorite $ LaTeX$ renderer yet. $$ I = begin{pmatrix}1&amp;0&amp;0&amp;0 0&amp;1&amp;0&amp;0 0&amp;0&amp;1&amp;0 0&amp;0&amp;0&amp;1 end{pmatrix} label{I_R4} $$ . BibTex . Fastpages has a built-in way to handle in-text references, but in order to minimize the manual work in copy-pasting sections of notebook to blog to thesis, I have decided to swap it out for a BibTex compliant renderer, as described by the fastpages team [3]. As you can see from this post, this works well. The big advantage is that the entire website uses a single references.bib file, so I can cite the same reference across multiple posts and end up with a single reference file when I want to consolidate multiple posts in a $ LaTeX$ thesis or a single post. . One caveat in in-text refencing is the usual [&lt;a class=&quot;latex_cit&quot; id=&quot;call-&lt;source&gt;&quot; href=&quot;#cit-&lt;source&gt;&quot;&gt;&lt;source&gt;&lt;/a&gt;] doesn&#39;t work and {% cite &lt;source&gt; %} is needed instead. This can be changed in bulk using the find and replace feature of any editor however. . Bibliography . [1]H. Husain and J. Howard, “Introducing fastpages,” fastpages. fast.ai, Feb-2020 [Online]. Available at: https://fastpages.fast.ai/fastpages/jupyter/2020/02/21/introducing-fastpages.html | [2]A. C., “Consider setting use_math to true by default,” fast.ai Forums. fast.ai, Apr-2020 [Online]. Available at: https://forums.fast.ai/t/consider-setting-use-math-to-true-by-default/64276/6 | [3]“Citations in Fastpages via BibTeX and jekyll-scholar,” fastpages. fast.ai, Jul-2020 [Online]. Available at: https://drscotthawley.github.io/devblog4/2020/07/01/Citations-Via-Bibtex.html | .",
            "url": "https://joristiebosch.github.io/blog/jupyter/2021/10/10/Introduction.html",
            "relUrl": "/jupyter/2021/10/10/Introduction.html",
            "date": " • Oct 10, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://joristiebosch.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://joristiebosch.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}